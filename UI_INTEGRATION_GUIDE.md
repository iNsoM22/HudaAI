# GraphAgent + UI Integration Guide

## âœ… Compatibility Status

The `graph_agent.py` and `page.py` are now **fully compatible** with dual-source retrieval (Quran + Hadith).

---

## ğŸ¯ Key Features

### 1. **Dual-Source Retrieval**
- Searches **both Quran and Hadith** by default
- Intelligent source selection based on query keywords
- Combines results seamlessly in the UI

### 2. **Streaming Support**
- Real-time updates as agent works
- Token-by-token answer generation
- Progress indicators for each tool execution

### 3. **Smart Query Analysis**
- Detects intent (factual, summary, comparison, explanation)
- Identifies Islamic terminology
- Determines optimal retrieval strategy
- Selects appropriate sources (Quran, Hadith, or both)

---

## ğŸ”§ API Reference

### GraphAgent Methods

#### `answer(query, thread_id="default", top_k=5, include_metrics=False)`
**Non-streaming mode** - Returns complete result after processing.

```python
agent = GraphAgent()
result = agent.answer(
    query="What does Islam teach about patience?",
    top_k=5,
    include_metrics=True
)

# Returns:
{
    "query": str,
    "answer": str,
    "contexts": List[Dict],  # Mixed Quran + Hadith
    "tools_used": List[str],
    "tool_outputs": Dict,
    "thread_id": str,
    "metrics": {  # If include_metrics=True
        "total_execution_time_ms": int,
        "context_count": int,
        "tool_count": int
    }
}
```

#### `answer_stream(query, thread_id="default", top_k=5)`
**Streaming mode** - Yields updates in real-time.

```python
agent = GraphAgent()
for update in agent.answer_stream(query="What hadiths mention charity?", top_k=5):
    event_type = update["type"]
    
    if event_type == "status":
        # Initial analysis
        print(update["message"])
        print(update["tools_selected"])
    
    elif event_type == "tool_start":
        # Tool execution starting
        print(f"Starting: {update['tool_name']}")
    
    elif event_type == "tool_complete":
        # Tool finished
        print(f"Completed: {update['tool_name']}")
        print(f"Output: {update['output']}")
    
    elif event_type == "synthesis_start":
        # LLM answer generation starting
        print("Generating answer...")
    
    elif event_type == "answer_token":
        # Stream tokens as they're generated
        print(update["token"], end="", flush=True)
    
    elif event_type == "complete":
        # Final result
        answer = update["answer"]
        contexts = update["contexts"]
        print(f"\nDone! {len(contexts)} contexts used")
    
    elif event_type == "error":
        print(f"Error: {update['error']}")
```

---

## ğŸ“Š Tool Outputs Structure

### Analysis Output
```python
{
    "intent": "factual" | "summary" | "comparison" | "explanation",
    "needs_summary": bool,
    "needs_context_expansion": bool,
    "search_quran": bool,
    "search_hadith": bool,
    "top_k": int,
    "reasoning": str
}
```

### Retrieval Output (per source)
```python
{
    "quran": {
        "count": int,
        "source": "quran"
    },
    "hadith": {
        "count": int,
        "source": "hadith"
    },
    "total_retrieved": int
}
```

### Context Structure

**Quran Context:**
```python
{
    "chunk_key": str,
    "surah_id": int,
    "verse_range": str,
    "text_english": str,
    "text_uthmani": str,
    "context_english": str,
    "context_uthmani": str,
    "similarity": float
}
```

**Hadith Context:**
```python
{
    "hadith_id": int,
    "book_name": str,
    "hadith_number": int,
    "chunk_text": str,
    "context_english": str,
    "context_arabic": str,
    "similarity": float,
    "status": str
}
```

---

## ğŸ¨ UI Compatibility

### Streaming Mode (page.py)
```python
from app.services.graph_agent import GraphAgent

agent = GraphAgent()

for update in agent.answer_stream(query, top_k=5):
    if update["type"] == "tool_complete":
        # Update UI with tool results
        if update["tool_name"] == "retrieval_quran":
            display_quran_results(update["output"])
        elif update["tool_name"] == "retrieval_hadith":
            display_hadith_results(update["output"])
    
    elif update["type"] == "answer_token":
        # Stream answer to UI
        answer_container.markdown(update["full_answer"])
    
    elif update["type"] == "complete":
        # Show final contexts
        display_contexts(update["contexts"])
```

### Non-Streaming Mode
```python
from app.services.graph_agent import GraphAgent

agent = GraphAgent()
result = agent.answer(query, top_k=5, include_metrics=True)

# Display execution steps
display_execution_steps(result)

# Show answer
st.markdown(result["answer"])

# Show contexts
display_contexts(result["contexts"])
```

---

## ğŸ§ª Testing

Run the integration test:
```bash
python test_ui_integration.py
```

This tests:
- âœ… Non-streaming mode
- âœ… Streaming mode
- âœ… Dual-source retrieval
- âœ… Query-specific source selection
- âœ… Error handling

---

## ğŸš€ Running the UI

```bash
streamlit run page.py
```

Features available in UI:
- ğŸ“ Natural language queries
- ğŸ”„ Real-time streaming updates
- ğŸ“š Mixed Quran + Hadith results
- ğŸ¯ Source-specific queries (mention "verse" or "hadith")
- ğŸ“Š Execution metrics and timing
- ğŸ” Quick search sidebar

---

## ğŸ’¡ Query Examples

### Dual-Source (Default)
```
"What does Islam teach about patience?"
"How should Muslims treat their parents?"
"Tell me about the importance of prayer"
```

### Quran-Specific
```
"Show me verses about Paradise"
"What does the Quran say about mercy?"
"Find Quranic ayahs mentioning prophets"
```

### Hadith-Specific
```
"What hadiths mention charity?"
"Show me sayings of the Prophet about kindness"
"Find hadiths from Bukhari about fasting"
```

---

## ğŸ”§ Customization

### Adjust Retrieval Count
```python
agent.answer(query, top_k=10)  # Retrieve 10 items per source
```

### Enable Metrics
```python
agent.answer(query, include_metrics=True)  # Get timing data
```

### Conversation History
```python
agent.answer(query, thread_id="user123")  # Track conversation
```

---

## âš¡ Performance

**Typical Response Times:**
- Query Analysis: ~500ms
- Quran Retrieval: ~300ms
- Hadith Retrieval: ~400ms
- Summarization: ~800ms
- Answer Generation: ~2-5s (streaming)

**Total**: ~4-7 seconds for complete response

---

## ğŸ› Troubleshooting

### No contexts retrieved
- Check database connection
- Verify embedding model is loaded
- Ensure query is not empty

### Wrong source selected
- Analysis uses keyword detection
- Add explicit terms: "verse", "hadith", "surah", "sunnah"
- Or let it search both sources

### Streaming not working
- Ensure using `answer_stream()` not `answer()`
- Check event types in your handler
- Verify LangChain streaming is enabled

---

## ğŸ“š Related Files

- `app/services/graph_agent.py` - Main agent implementation
- `app/utils/retrieval.py` - Database queries and embedding
- `page.py` - Streamlit UI
- `test_ui_integration.py` - Integration tests
- `test_graph_agent_dual_source.py` - Dual-source tests

---

**Status**: âœ… Production Ready

The system is fully integrated and tested for both streaming and non-streaming modes with dual-source retrieval support.
